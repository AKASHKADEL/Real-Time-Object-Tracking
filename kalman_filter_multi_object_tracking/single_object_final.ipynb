{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from common import dprint\n",
    "import os\n",
    "\n",
    "# from detectors import Detectors\n",
    "# from tracker import Tracker\n",
    "# from kalman_filter import KalmanFilter\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug = 0\n",
    "\n",
    "class Detectors(object):\n",
    "    \"\"\"Detectors class to detect objects in video frame\n",
    "    Attributes:\n",
    "        None\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize variables used by Detectors class\n",
    "        Args:\n",
    "            None\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    def Detect(self, frame, width, height, cx, cy):\n",
    "        \"\"\"Detect objects in video frame using following pipeline\n",
    "            - Convert captured frame from BGR to GRAY\n",
    "            - Perform Background Subtraction\n",
    "            - Detect edges using Canny Edge Detection\n",
    "              http://docs.opencv.org/trunk/da/d22/tutorial_py_canny.html\n",
    "            - Retain only edges within the threshold\n",
    "            - Find contours\n",
    "            - Find centroids for each valid contours\n",
    "        Args:\n",
    "            frame: single video frame\n",
    "        Return:\n",
    "            centers: vector of object centroids in a frame\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert BGR to GRAY\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if (debug == 1):\n",
    "            cv2.imshow('gray', gray)\n",
    "\n",
    "        # Perform Background Subtraction\n",
    "        fgmask = self.fgbg.apply(gray)\n",
    "\n",
    "        if (debug == 0):\n",
    "            cv2.imshow('bgsub', fgmask)\n",
    "\n",
    "        # Detect edges\n",
    "        edges = cv2.Canny(fgmask, 50, 190, 3)\n",
    "\n",
    "        if (debug == 1):\n",
    "            cv2.imshow('Edges', edges)\n",
    "\n",
    "        # Retain only edges within the threshold\n",
    "        ret, thresh = cv2.threshold(edges, 127, 255, 0)\n",
    "        #ret, thresh = cv2.threshold(edges, 127, 255, cv2.THRESH_BINARY)\n",
    "        #print(thresh)\n",
    "        # Find contours\n",
    "        _, contours, hierarchy = cv2.findContours(thresh,\n",
    "                                                  cv2.RETR_EXTERNAL,\n",
    "                                                  cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if (debug == 0):\n",
    "            cv2.imshow('thresh', thresh)\n",
    "\n",
    "        centers = []  # vector of object centroids in a frame\n",
    "        # we only care about centroids with size of bug in this example\n",
    "        # recommended to be tunned based on expected object size for\n",
    "        # improved performance\n",
    "        min_cx, min_cy = 0, 0\n",
    "        min_dist = np.inf\n",
    "        dimensions = []\n",
    "        #blob_radius_thresh = assigned_threshold\n",
    "        # Find centroid for each valid contours\n",
    "        for cnt in contours:\n",
    "            try:\n",
    "                # Calculate and draw circle\n",
    "                (x, y), radius = cv2.minEnclosingCircle(cnt)\n",
    "                centeroid = (int(x), int(y))\n",
    "                radius = int(radius)\n",
    "                if radius > 15:\n",
    "                    if np.sqrt(((cx-x)**2 + (cy-y)**2)) < min_dist:\n",
    "                        min_cx, min_cy = x, y\n",
    "                        min_dist = np.sqrt(((cx-x)**2 + (cy-y)**2))\n",
    "            except ZeroDivisionError:\n",
    "                pass\n",
    "            \n",
    "        cv2.rectangle(frame, (int(min_cx)-width, int(min_cy)-height), (int(min_cx)+width, int(min_cy)+height), (255,0,0), 2, 1)\n",
    "#         rect = cv2.minAreaRect(cnt)\n",
    "#                     (x, y), (w, h), angle = rect\n",
    "#                     #if (w > blob_width_thresh and h > blob_height_thresh):\n",
    "#                     box = np.int0(cv2.boxPoints(rect))\n",
    "#                     cv2.drawContours(frame, [box], 0, (0,255,0), 2)\n",
    "#                     b = np.array([[x], [y]])\n",
    "#                     centers.append(np.round(b))\n",
    "#                     dimensions.append((w,h))\n",
    "\n",
    "        # show contours of tracking objects\n",
    "        # cv2.imshow('Track Bugs', frame)\n",
    "\n",
    "        return int(min_cx), int(min_cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    \"\"\"Kalman Filter class keeps track of the estimated state of\n",
    "    the system and the variance or uncertainty of the estimate.\n",
    "    Predict and Correct methods implement the functionality\n",
    "    Reference: https://en.wikipedia.org/wiki/Kalman_filter\n",
    "    Attributes: None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize variable used by Kalman Filter class\n",
    "        Args:\n",
    "            None\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.dt = 0.005  # delta time\n",
    "\n",
    "        self.A = np.array([[1, 0], [0, 1]])  # matrix in observation equations\n",
    "        self.u = np.zeros((2, 1))  # previous state vector\n",
    "\n",
    "        # (x,y) tracking object center\n",
    "        self.b = np.array([[0], [255]])  # vector of observations\n",
    "\n",
    "        self.P = np.diag((3.0, 3.0))  # covariance matrix\n",
    "        self.F = np.array([[1.0, self.dt], [0.0, 1.0]])  # state transition mat\n",
    "\n",
    "        self.Q = np.eye(self.u.shape[0])  # process noise matrix\n",
    "        self.R = np.eye(self.b.shape[0])  # observation noise matrix\n",
    "        self.lastResult = np.array([[0], [255]])\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predict state vector u and variance of uncertainty P (covariance).\n",
    "            where,\n",
    "            u: previous state vector\n",
    "            P: previous covariance matrix\n",
    "            F: state transition matrix\n",
    "            Q: process noise matrix\n",
    "        Equations:\n",
    "            u'_{k|k-1} = Fu'_{k-1|k-1}\n",
    "            P_{k|k-1} = FP_{k-1|k-1} F.T + Q\n",
    "            where,\n",
    "                F.T is F transpose\n",
    "        Args:\n",
    "            None\n",
    "        Return:\n",
    "            vector of predicted state estimate\n",
    "        \"\"\"\n",
    "        # Predicted state estimate\n",
    "        self.u = np.round(np.dot(self.F, self.u))\n",
    "        # Predicted estimate covariance\n",
    "        self.P = np.dot(self.F, np.dot(self.P, self.F.T)) + self.Q\n",
    "        self.lastResult = self.u  # same last predicted result\n",
    "        return self.u\n",
    "\n",
    "    def correct(self, b, flag):\n",
    "        \"\"\"Correct or update state vector u and variance of uncertainty P (covariance).\n",
    "        where,\n",
    "        u: predicted state vector u\n",
    "        A: matrix in observation equations\n",
    "        b: vector of observations\n",
    "        P: predicted covariance matrix\n",
    "        Q: process noise matrix\n",
    "        R: observation noise matrix\n",
    "        Equations:\n",
    "            C = AP_{k|k-1} A.T + R\n",
    "            K_{k} = P_{k|k-1} A.T(C.Inv)\n",
    "            u'_{k|k} = u'_{k|k-1} + K_{k}(b_{k} - Au'_{k|k-1})\n",
    "            P_{k|k} = P_{k|k-1} - K_{k}(CK.T)\n",
    "            where,\n",
    "                A.T is A transpose\n",
    "                C.Inv is C inverse\n",
    "        Args:\n",
    "            b: vector of observations\n",
    "            flag: if \"true\" prediction result will be updated else detection\n",
    "        Return:\n",
    "            predicted state vector u\n",
    "        \"\"\"\n",
    "\n",
    "        if not flag:  # update using prediction\n",
    "            self.b = self.lastResult\n",
    "        else:  # update using detection\n",
    "            self.b = b\n",
    "        C = np.dot(self.A, np.dot(self.P, self.A.T)) + self.R\n",
    "        K = np.dot(self.P, np.dot(self.A.T, np.linalg.inv(C)))\n",
    "\n",
    "        self.u = np.round(self.u + np.dot(K, (self.b - np.dot(self.A,\n",
    "                                                              self.u))))\n",
    "        self.P = self.P - np.dot(K, np.dot(C, K.T))\n",
    "        self.lastResult = self.u\n",
    "        return self.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Track(object):\n",
    "    \"\"\"Track class for every object to be tracked\n",
    "    Attributes:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prediction, trackIdCount):\n",
    "        \"\"\"Initialize variables used by Track class\n",
    "        Args:\n",
    "            prediction: predicted centroids of object to be tracked\n",
    "            trackIdCount: identification of each track object\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.track_id = trackIdCount  # identification of each track object\n",
    "        self.KF = KalmanFilter()  # KF instance to track this object\n",
    "        self.prediction = np.asarray(prediction)  # predicted centroids (x,y)\n",
    "        self.skipped_frames = 0  # number of frames skipped undetected\n",
    "        self.trace = []  # trace path\n",
    "\n",
    "\n",
    "class Tracker(object):\n",
    "    \"\"\"Tracker class that updates track vectors of object tracked\n",
    "    Attributes:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dist_thresh, max_frames_to_skip, max_trace_length,\n",
    "                 trackIdCount):\n",
    "        \"\"\"Initialize variable used by Tracker class\n",
    "        Args:\n",
    "            dist_thresh: distance threshold. When exceeds the threshold,\n",
    "                         track will be deleted and new track is created\n",
    "            max_frames_to_skip: maximum allowed frames to be skipped for\n",
    "                                the track object undetected\n",
    "            max_trace_lenght: trace path history length\n",
    "            trackIdCount: identification of each track object\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.dist_thresh = dist_thresh\n",
    "        self.max_frames_to_skip = max_frames_to_skip\n",
    "        self.max_trace_length = max_trace_length\n",
    "        self.tracks = []\n",
    "        self.trackIdCount = trackIdCount\n",
    "\n",
    "    def Update(self, detections):\n",
    "        \"\"\"Update tracks vector using following steps:\n",
    "            - Create tracks if no tracks vector found\n",
    "            - Calculate cost using sum of square distance\n",
    "              between predicted vs detected centroids\n",
    "            - Using Hungarian Algorithm assign the correct\n",
    "              detected measurements to predicted tracks\n",
    "              https://en.wikipedia.org/wiki/Hungarian_algorithm\n",
    "            - Identify tracks with no assignment, if any\n",
    "            - If tracks are not detected for long time, remove them\n",
    "            - Now look for un_assigned detects\n",
    "            - Start new tracks\n",
    "            - Update KalmanFilter state, lastResults and tracks trace\n",
    "        Args:\n",
    "            detections: detected centroids of object to be tracked\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        # Create tracks if no tracks vector found\n",
    "        if (len(self.tracks) == 0):\n",
    "            for i in range(len(detections)):\n",
    "                track = Track(detections[i], self.trackIdCount)\n",
    "                self.trackIdCount += 1\n",
    "                self.tracks.append(track)\n",
    "\n",
    "        # Calculate cost using sum of square distance between\n",
    "        # predicted vs detected centroids\n",
    "        N = len(self.tracks)\n",
    "        M = len(detections)\n",
    "        cost = np.zeros(shape=(N, M))   # Cost matrix\n",
    "        for i in range(len(self.tracks)):\n",
    "            for j in range(len(detections)):\n",
    "                try:\n",
    "                    diff = self.tracks[i].prediction - detections[j]\n",
    "                    distance = np.sqrt(diff[0][0]*diff[0][0] +\n",
    "                                       diff[1][0]*diff[1][0])\n",
    "                    cost[i][j] = distance\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # Let's average the squared ERROR\n",
    "        cost = (0.5) * cost\n",
    "        # Using Hungarian Algorithm assign the correct detected measurements\n",
    "        # to predicted tracks\n",
    "        assignment = []\n",
    "        for _ in range(N):\n",
    "            assignment.append(-1)\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "        for i in range(len(row_ind)):\n",
    "            assignment[row_ind[i]] = col_ind[i]\n",
    "            \n",
    "        # Identify tracks with no assignment, if any\n",
    "        un_assigned_tracks = []\n",
    "        for i in range(len(assignment)):\n",
    "            if (assignment[i] != -1):\n",
    "                # check for cost distance threshold.\n",
    "                # If cost is very high then un_assign (delete) the track\n",
    "                if (cost[i][assignment[i]] > self.dist_thresh):\n",
    "                    assignment[i] = -1\n",
    "                    un_assigned_tracks.append(i)\n",
    "                pass\n",
    "            else:\n",
    "                self.tracks[i].skipped_frames += 1\n",
    "\n",
    "        # If tracks are not detected for long time, remove them\n",
    "        del_tracks = []\n",
    "        for i in range(len(self.tracks)):\n",
    "            if (self.tracks[i].skipped_frames > self.max_frames_to_skip):\n",
    "                del_tracks.append(i)\n",
    "        if len(del_tracks) > 0:  # only when skipped frame exceeds max\n",
    "            for id in del_tracks:\n",
    "                if id < len(self.tracks):\n",
    "                    del self.tracks[id]\n",
    "                    del assignment[id]\n",
    "                else:\n",
    "                    dprint(\"ERROR: id is greater than length of tracks\")\n",
    "\n",
    "        # Now look for un_assigned detects\n",
    "        un_assigned_detects = []\n",
    "        for i in range(len(detections)):\n",
    "                if i not in assignment:\n",
    "                    un_assigned_detects.append(i)\n",
    "\n",
    "        # Start new tracks\n",
    "        if(len(un_assigned_detects) != 0):\n",
    "            for i in range(len(un_assigned_detects)):\n",
    "                track = Track(detections[un_assigned_detects[i]],\n",
    "                              self.trackIdCount)\n",
    "                self.trackIdCount += 1\n",
    "                self.tracks.append(track)\n",
    "\n",
    "        # Update KalmanFilter state, lastResults and tracks trace\n",
    "        for i in range(len(assignment)):\n",
    "            self.tracks[i].KF.predict()\n",
    "\n",
    "            if(assignment[i] != -1):\n",
    "                self.tracks[i].skipped_frames = 0\n",
    "                self.tracks[i].prediction = self.tracks[i].KF.correct(\n",
    "                                            detections[assignment[i]], 1)\n",
    "            else:\n",
    "                self.tracks[i].prediction = self.tracks[i].KF.correct(\n",
    "                                            np.array([[0], [0]]), 0)\n",
    "\n",
    "            if(len(self.tracks[i].trace) > self.max_trace_length):\n",
    "                for j in range(len(self.tracks[i].trace) -\n",
    "                               self.max_trace_length):\n",
    "                    del self.tracks[i].trace[j]\n",
    "\n",
    "            self.tracks[i].trace.append(self.tracks[i].prediction)\n",
    "            self.tracks[i].KF.lastResult = self.tracks[i].prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frames(evaluation_name):\n",
    "    video_folder = os.path.join('data', 'vot2016', evaluation_name)\n",
    "    frame_name_list = [f for f in os.listdir(video_folder) if f.endswith(\".jpg\")]\n",
    "    frame_name_list = [os.path.join('data', 'vot2016', evaluation_name, '') + s for s in frame_name_list]\n",
    "    frame_name_list.sort()\n",
    "    gt_file = os.path.join(video_folder, 'groundtruth.txt')\n",
    "    gt = np.genfromtxt(gt_file, delimiter=',')\n",
    "    return frame_name_list, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(name):\n",
    "    \"\"\"Main function for multi object tracking\n",
    "    Usage:\n",
    "        $ python2.7 objectTracking.py\n",
    "    Pre-requisite:\n",
    "        - Python2.7\n",
    "        - Numpy\n",
    "        - SciPy\n",
    "        - Opencv 3.0 for Python\n",
    "    Args:\n",
    "        None\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    frame_name_list, gt = get_frames(name)\n",
    "    frame_name_list = frame_name_list[:160]\n",
    "    gt = gt[:160]\n",
    "    total_no_of_frames = len(frame_name_list)\n",
    "    \n",
    "    # Create Object Detector\n",
    "    detector = Detectors()\n",
    "\n",
    "    # Create Object Tracker\n",
    "    tracker = Tracker(160, 30, 5, 100)\n",
    "\n",
    "    # Variables initialization\n",
    "    skip_frame_count = 0\n",
    "    track_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
    "                    (0, 255, 255), (255, 0, 255), (255, 127, 255),\n",
    "                    (127, 0, 255), (127, 0, 127)]\n",
    "    pause = False\n",
    "\n",
    "    frame_num = 0\n",
    "    estimated_coordinates = []\n",
    "    \n",
    "    bbox = (287, 23, 86, 320)\n",
    "    frame = cv2.imread(frame_name_list[0])\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    "    cx, cy = int(bbox[0]) + int(int(bbox[2])/2), int(bbox[1]) + int(int(bbox[3])/2)\n",
    "    width, height = int(bbox[2]), int(bbox[3])\n",
    "    tracker.Update([np.array([[cx], [cy]])])\n",
    "    while(total_no_of_frames - frame_num > 1):\n",
    "        frame_num += 1\n",
    "        frame = cv2.imread(frame_name_list[frame_num])\n",
    "        orig_frame = copy.copy(frame)\n",
    "        \n",
    "        cx, cy = detector.Detect(frame, width, height, cx, cy)\n",
    "\n",
    "        centers = []\n",
    "        center = np.array([[cx], [cy]])\n",
    "        centers.append(center)\n",
    "        estimated_coordinates.append([cx, cy, width, height])\n",
    "        \n",
    "        # If centroids are detected then track them\n",
    "        if (len(centers) > 0):\n",
    "\n",
    "            # Track object using Kalman Filter\n",
    "            tracker.Update(centers)\n",
    "\n",
    "            # For identified object tracks draw tracking line\n",
    "            # Use various colors to indicate different track_id\n",
    "            for i in range(len(tracker.tracks)):\n",
    "                if (len(tracker.tracks[i].trace) > 1):\n",
    "                    for j in range(len(tracker.tracks[i].trace)-1):\n",
    "                        # Draw trace line\n",
    "                        x1 = tracker.tracks[i].trace[j][0][0]\n",
    "                        y1 = tracker.tracks[i].trace[j][1][0]\n",
    "                        x2 = tracker.tracks[i].trace[j+1][0][0]\n",
    "                        y2 = tracker.tracks[i].trace[j+1][1][0]\n",
    "                        clr = tracker.tracks[i].track_id % 9 #color\n",
    "                        cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)),\n",
    "                                 track_colors[clr], 2) #draw the line\n",
    "\n",
    "            # Display the resulting tracking frame\n",
    "            cv2.imshow('Tracking', frame)\n",
    "\n",
    "        # Display the original frame\n",
    "        cv2.imshow('Original', orig_frame)\n",
    "\n",
    "        # Slower the FPS\n",
    "        cv2.waitKey(50)\n",
    "\n",
    "        # Check for key strokes\n",
    "        k = cv2.waitKey(50) & 0xff\n",
    "        if k == 27:  # 'esc' key has been pressed, exit program.\n",
    "            break\n",
    "        if k == 112:  # 'p' has been pressed. this will pause/resume the code.\n",
    "            pause = not pause\n",
    "            if (pause is True):\n",
    "                print(\"Code is paused. Press 'p' to resume..\")\n",
    "                while (pause is True):\n",
    "                    # stay in this loop until\n",
    "                    key = cv2.waitKey(30) & 0xff\n",
    "                    if key == 112:\n",
    "                        pause = False\n",
    "                        print(\"Resume code..!!\")\n",
    "                        break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    #cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return estimated_coordinates, gt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # execute main\n",
    "    name = 'sphere'\n",
    "    estimated_coordinates, gt = main(name)\n",
    "    for i in range(len(estimated_coordinates)):\n",
    "        estimated_coordinates[i][0] -= estimated_coordinates[i][2]/2\n",
    "        estimated_coordinates[i][1] -= estimated_coordinates[i][3]/2\n",
    "    gt = gt[1:] # the first frame is not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.77358490566 0.880503144654 23.0726505297\n"
     ]
    }
   ],
   "source": [
    "_, precision, precision_auc, iou = _compile_results(gt, np.array(estimated_coordinates), 20)\n",
    "print(precision, precision_auc, iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _compile_results(gt, bboxes, dist_threshold):\n",
    "    l = np.size(bboxes, 0)\n",
    "    gt4 = np.zeros((l, 4))\n",
    "    new_distances = np.zeros(l)\n",
    "    new_ious = np.zeros(l)\n",
    "    n_thresholds = 50\n",
    "    precisions_ths = np.zeros(n_thresholds)\n",
    "\n",
    "    for i in range(l):\n",
    "        gt4[i, :] = region_to_bbox(gt[i, :], center=False)\n",
    "        new_distances[i] = _compute_distance(bboxes[i, :], gt4[i, :])\n",
    "        new_ious[i] = _compute_iou(bboxes[i, :], gt4[i, :])\n",
    "\n",
    "    # what's the percentage of frame in which center displacement is inferior to given threshold? (OTB metric)\n",
    "    precision = sum(new_distances < dist_threshold)/np.size(new_distances) * 100\n",
    "\n",
    "    # find above result for many thresholds, then report the AUC\n",
    "    thresholds = np.linspace(0, 25, n_thresholds+1)\n",
    "    thresholds = thresholds[-n_thresholds:]\n",
    "    # reverse it so that higher values of precision goes at the beginning\n",
    "    thresholds = thresholds[::-1]\n",
    "    for i in range(n_thresholds):\n",
    "        precisions_ths[i] = sum(new_distances < thresholds[i])/np.size(new_distances)\n",
    "\n",
    "    # integrate over the thresholds\n",
    "    precision_auc = np.trapz(precisions_ths)    \n",
    "\n",
    "    # per frame averaged intersection over union (OTB metric)\n",
    "    iou = np.mean(new_ious) * 100\n",
    "    return l, precision, precision_auc, iou\n",
    "\n",
    "def _compute_distance(boxA, boxB):\n",
    "    a = np.array((boxA[0]+boxA[2]/2, boxA[1]+boxA[3]/2))\n",
    "    b = np.array((boxB[0]+boxB[2]/2, boxB[1]+boxB[3]/2))\n",
    "    dist = np.linalg.norm(a - b)\n",
    "\n",
    "    assert dist >= 0\n",
    "    assert dist != float('Inf')\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def _compute_iou(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "\n",
    "    if xA < xB and yA < yB:\n",
    "        # compute the area of intersection rectangle\n",
    "        interArea = (xB - xA) * (yB - yA)\n",
    "        # compute the area of both the prediction and ground-truth\n",
    "        # rectangles\n",
    "        boxAArea = boxA[2] * boxA[3]\n",
    "        boxBArea = boxB[2] * boxB[3]\n",
    "        # compute the intersection over union by taking the intersection\n",
    "        # area and dividing it by the sum of prediction + ground-truth\n",
    "        # areas - the intersection area\n",
    "        iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    else:\n",
    "        iou = 0\n",
    "\n",
    "    assert iou >= 0\n",
    "    assert iou <= 1.01\n",
    "\n",
    "    return iou\n",
    "def region_to_bbox(region, center=True):\n",
    "\n",
    "    n = len(region)\n",
    "    assert n==4 or n==8, ('GT region format is invalid, should have 4 or 8 entries.')\n",
    "\n",
    "    if n==4:\n",
    "        return _rect(region, center)\n",
    "    else:\n",
    "        return _poly(region, center)\n",
    "\n",
    "# we assume the grountruth bounding boxes are saved with 0-indexing\n",
    "def _rect(region, center):\n",
    "    \n",
    "    if center:\n",
    "        x = region[0]\n",
    "        y = region[1]\n",
    "        w = region[2]\n",
    "        h = region[3]\n",
    "        cx = x+w/2\n",
    "        cy = y+h/2\n",
    "        return cx, cy, w, h\n",
    "    else:\n",
    "        #region[0] -= 1\n",
    "        #region[1] -= 1\n",
    "        return region\n",
    "\n",
    "\n",
    "def _poly(region, center):\n",
    "    cx = np.mean(region[::2])\n",
    "    cy = np.mean(region[1::2])\n",
    "    x1 = np.min(region[::2])\n",
    "    x2 = np.max(region[::2])\n",
    "    y1 = np.min(region[1::2])\n",
    "    y2 = np.max(region[1::2])\n",
    "    A1 = np.linalg.norm(region[0:2] - region[2:4]) * np.linalg.norm(region[2:4] - region[4:6])\n",
    "    A2 = (x2 - x1) * (y2 - y1)\n",
    "    s = np.sqrt(A1/A2)\n",
    "    w = s * (x2 - x1) + 1\n",
    "    h = s * (y2 - y1) + 1\n",
    "\n",
    "    if center:\n",
    "        return cx, cy, w, h\n",
    "    else:\n",
    "        return cx-w/2, cy-h/2, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
